{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Libraries\n",
    "Install necessary libraries such as OpenCV, TensorFlow/PyTorch, Pandas, and Matplotlib/Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.6.0)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (6.0.0)\n",
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (8.3.75)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from opencv-python-headless) (2.1.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (4.55.8)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from plotly) (1.27.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (1.15.2)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /Users/hunterantal/Library/Python/3.13/lib/python/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless torch pandas matplotlib plotly ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as OpenCV, TensorFlow/PyTorch, Pandas, and Matplotlib/Plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV for frame extraction and image processing\n",
    "import torch  # PyTorch for bird classification\n",
    "import pandas as pd  # Pandas for data storage and processing\n",
    "import matplotlib.pyplot as plt  # Matplotlib for visualization\n",
    "import plotly.express as px  # Plotly for interactive visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame Extraction\n",
    "Load a time-lapse video, extract frames at a configurable interval, and save the extracted frames for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 25 frames from the video.\n"
     ]
    }
   ],
   "source": [
    "import cv2  # OpenCV for frame extraction and image processing\n",
    "\n",
    "# Function to extract frames from video\n",
    "def extract_frames(video_path, output_folder, interval=1):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if video opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "    \n",
    "    # Get the total number of frames in the video\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Frame counter\n",
    "    frame_count = 0\n",
    "    \n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # If frame is read correctly\n",
    "        if ret:\n",
    "            # Save frame at the specified interval\n",
    "            if frame_count % interval == 0:\n",
    "                frame_filename = f\"{output_folder}/frame_{frame_count}.jpg\"\n",
    "                cv2.imwrite(frame_filename, frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    print(f\"Extracted {frame_count // interval} frames from the video.\")\n",
    "\n",
    "# Example usage\n",
    "video_path = '/Users/hunterantal/Development/BirdWatcher/Input/Birds(17-02-2025).MOV'\n",
    "output_folder = 'extracted_frames'\n",
    "extract_frames(video_path, output_folder, interval=30)  # Extract 1 frame per second (assuming 30 fps video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird Detection\n",
    "Use a pre-trained object detection model (e.g., YOLOv8 or Faster R-CNN) to locate birds in each frame and draw bounding boxes around detected birds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n summary: 225 layers, 3,157,200 parameters, 0 gradients, 8.9 GFLOPs\n",
      "WARNING ⚠️ 'source' is missing. Using 'source=/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/assets'.\n",
      "\n",
      "image 1/2 /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/assets/bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 61.4ms\n",
      "image 2/2 /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/ultralytics/assets/zidane.jpg: 384x640 2 persons, 1 tie, 45.3ms\n",
      "Speed: 1.3ms preprocess, 53.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@2626.505] global loadsave.cpp:268 findDecoder imread_('extracted_frames/frame_0.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgcodecs/src/loadsave.cpp:929: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m frame_with_boxes \u001b[38;5;241m=\u001b[39m draw_bounding_boxes(frame, boxes, labels)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Save the frame with bounding boxes\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetected_birds_frame_0.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_with_boxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgcodecs/src/loadsave.cpp:929: error: (-215:Assertion failed) !_img.empty() in function 'imwrite'\n"
     ]
    }
   ],
   "source": [
    "import cv2  # OpenCV for frame extraction and image processing\n",
    "import torch  # PyTorch for bird classification\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLOv8n model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Display model information (optional)\n",
    "model.info()\n",
    "\n",
    "# Function to detect birds in a frame\n",
    "def detect_birds(frame):\n",
    "    # Perform inference\n",
    "    results = model(frame)\n",
    "    \n",
    "    # Extract bounding boxes and labels\n",
    "    boxes = results.xyxy[0].numpy()  # Bounding boxes\n",
    "    labels = results.names  # Class labels\n",
    "    \n",
    "    return boxes, labels\n",
    "\n",
    "# Function to draw bounding boxes on the frame\n",
    "def draw_bounding_boxes(frame, boxes, labels):\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        label = labels[int(cls)]\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        \n",
    "        # Put label\n",
    "        cv2.putText(frame, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# Example usage\n",
    "frame_path = 'extracted_frames/frame_0.jpg'\n",
    "frame = cv2.imread(frame_path)\n",
    "\n",
    "# Detect birds in the frame\n",
    "results = model(frame)\n",
    "boxes = results[0].boxes.data.cpu().numpy()  # Get boxes as numpy array\n",
    "labels = results[0].names  # Get class labels\n",
    "\n",
    "# Draw bounding boxes on the frame\n",
    "frame_with_boxes = draw_bounding_boxes(frame, boxes, labels)\n",
    "\n",
    "# Save the frame with bounding boxes\n",
    "cv2.imwrite('detected_birds_frame_0.jpg', frame_with_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species Classification\n",
    "Use a deep learning model trained on bird species to classify detected birds and implement color-based filtering for species differentiation if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Load pre-trained bird species classification model\n",
    "# Assuming a model trained on bird species is available\n",
    "classification_model = torch.load('path_to_your_bird_classification_model.pth')\n",
    "classification_model.eval()\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to classify bird species in a detected bounding box\n",
    "def classify_bird_species(frame, boxes):\n",
    "    species_list = []\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        bird_crop = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "        bird_image = Image.fromarray(cv2.cvtColor(bird_crop, cv2.COLOR_BGR2RGB))\n",
    "        bird_tensor = transform(bird_image).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = classification_model(bird_tensor)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            species = predicted.item()\n",
    "            species_list.append(species)\n",
    "    \n",
    "    return species_list\n",
    "\n",
    "# Example usage\n",
    "frame_path = 'extracted_frames/frame_0.jpg'\n",
    "frame = cv2.imread(frame_path)\n",
    "\n",
    "# Detect birds in the frame\n",
    "boxes, labels = detect_birds(frame)\n",
    "\n",
    "# Classify bird species in the detected bounding boxes\n",
    "species_list = classify_bird_species(frame, boxes)\n",
    "\n",
    "# Print the detected species\n",
    "print(\"Detected species:\", species_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting & Data Storage\n",
    "Track unique birds to avoid duplicate counting across frames and store species counts in a CSV or JSON file for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to count unique birds and store species counts in a CSV or JSON file\n",
    "def count_and_store_bird_data(frames_folder, output_file, output_format='csv'):\n",
    "    bird_data = []\n",
    "    \n",
    "    # Loop through the extracted frames\n",
    "    for frame_filename in os.listdir(frames_folder):\n",
    "        frame_path = os.path.join(frames_folder, frame_filename)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        \n",
    "        # Detect birds in the frame\n",
    "        boxes, labels = detect_birds(frame)\n",
    "        \n",
    "        # Classify bird species in the detected bounding boxes\n",
    "        species_list = classify_bird_species(frame, boxes)\n",
    "        \n",
    "        # Track unique birds and count occurrences\n",
    "        for species in species_list:\n",
    "            bird_data.append({\n",
    "                'frame': frame_filename,\n",
    "                'species': species,\n",
    "                'timestamp': frame_filename.split('_')[1].split('.')[0]  # Assuming frame filenames are in the format 'frame_<timestamp>.jpg'\n",
    "            })\n",
    "    \n",
    "    # Convert bird data to a DataFrame\n",
    "    bird_df = pd.DataFrame(bird_data)\n",
    "    \n",
    "    # Store data in the specified format\n",
    "    if output_format == 'csv':\n",
    "        bird_df.to_csv(output_file, index=False)\n",
    "    elif output_format == 'json':\n",
    "        bird_df.to_json(output_file, orient='records', lines=True)\n",
    "    else:\n",
    "        print(\"Unsupported output format. Please choose 'csv' or 'json'.\")\n",
    "\n",
    "# Example usage\n",
    "frames_folder = 'extracted_frames'\n",
    "output_file = 'bird_data.csv'\n",
    "count_and_store_bird_data(frames_folder, output_file, output_format='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "Generate a time-series plot showing species counts over time and optionally create a dashboard for real-time visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Function to generate a time-series plot showing species counts over time\n",
    "def plot_species_counts(csv_file):\n",
    "    # Load the bird data from CSV\n",
    "    bird_df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    bird_df['timestamp'] = pd.to_datetime(bird_df['timestamp'], unit='s')\n",
    "    \n",
    "    # Group by timestamp and species to count occurrences\n",
    "    species_counts = bird_df.groupby(['timestamp', 'species']).size().reset_index(name='count')\n",
    "    \n",
    "    # Pivot the data for plotting\n",
    "    species_pivot = species_counts.pivot(index='timestamp', columns='species', values='count').fillna(0)\n",
    "    \n",
    "    # Plot the data using Matplotlib\n",
    "    species_pivot.plot(kind='line', figsize=(12, 6))\n",
    "    plt.title('Bird Species Counts Over Time')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Count')\n",
    "    plt.legend(title='Species')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Function to create an interactive dashboard for real-time visualization\n",
    "def create_dashboard(csv_file):\n",
    "    # Load the bird data from CSV\n",
    "    bird_df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    bird_df['timestamp'] = pd.to_datetime(bird_df['timestamp'], unit='s')\n",
    "    \n",
    "    # Group by timestamp and species to count occurrences\n",
    "    species_counts = bird_df.groupby(['timestamp', 'species']).size().reset_index(name='count')\n",
    "    \n",
    "    # Create an interactive line plot using Plotly\n",
    "    fig = px.line(species_counts, x='timestamp', y='count', color='species', title='Bird Species Counts Over Time')\n",
    "    fig.show()\n",
    "\n",
    "# Example usage\n",
    "csv_file = 'bird_data.csv'\n",
    "plot_species_counts(csv_file)\n",
    "create_dashboard(csv_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
